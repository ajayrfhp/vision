{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why\n",
    "    - DNNs are hard to intrepret\n",
    "    - We cannot attribute predictions of a standard classifier\n",
    "        - Hard to understand why the model behaves the way it does\n",
    "    - Intrepretability is critical in all applications of value\n",
    "- What\n",
    "    - What is intepretability\n",
    "        - **the concept of interpretability refers to the way in which evidence from small image patches is integrated to reach an image-level decision**\n",
    "- Novel contributions\n",
    "    - Combine interpretability of bag of words model with flexibility of DNNs (BagNets)\n",
    "        - Achieve high accuracy comparable to DNN based systems with the interpretability\n",
    "    - Demonstrate similarities between decision making of bagnet and DNN based methods\n",
    "- Literature review\n",
    "    - Prerequisites\n",
    "        - Bag of visual words model\n",
    "        - Standard DNNs\n",
    "        - Interpretabble DNNs\n",
    "    - \n",
    "- How\n",
    "- Results\n",
    "- Conclusions\n",
    "    - Possible to build a system that is interpretable and powerful\n",
    "    - Standard DNNs behave in a way similar to bagnet\n",
    "    - Current architectures are making image decisions based on a large number of statistical regularities\n",
    "        - they are not making decisions using casuality\n",
    "- The story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
